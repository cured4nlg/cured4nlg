## Set up environment and libraries.

Create and activate a virtual environment using Anaconda.
```
conda create -n cured4nlg python=3.8
conda activate cured4nlg
```

Install the required libraries.
```
pip install -r requirements.txt
```

Mac OS users might also need to install `poppler` and `tesseract` for data extraction from pdfs. It can be installed using [homebrew](https://brew.sh).
```
brew install poppler tesseract
```

## Extraction of Tables and Texts from the Situation Report PDF

### Extracting Global Table
1. Manually fill the `global-table` spreadsheet and export it as a `.tsv` file.
2. Run the script to format the data in the same way as presented in the original PDF.
`python parse_global.py < $global-table.tsv | sed 's/(-%)//g' | sed 's/-%/-/g' > $date-$global.tsv`

### Extracting Regional Tables
1. Run the script to convert the pdf document into images.
`python pdf_to_img.py $path_to_pdf`

2. Run the script over the pages containing tables to extract them as a plaintext file.
`python extract_table.py $page.bmp > $page.txt`

3. Edit the plaintext files in a text editor and save the data as a `.tsv` file. This is usually the most time intensive step as it takes a few minutes to manually process all the tables in a report to get them into the correct structure and format.

### Extracting Texts
1. The texts are simply copied from the PDF to be pasted into a text editor and saved as a `.txt` file.
2. The reports use a `<space>` as a digits-separator to represent large numbers which are removed using a regular expression.
3. To create the `clean` version of a text, remove any sentences which cannot be realized from the information contained in the tables.


## Baselines

### Template Baseline

The templated baseline output is generated by the script `template.py`.


### Hierarchical Model

The data for the hierarchical model is created by the script `create_hierarchical.py` and pre-processing and training is done by following the steps in the original [repo](https://github.com/KaijuML/data-to-text-hierarchical).


### T5 Baseline

The scripts for creating the data, training and generation can be found in the `t5/` directory.


## Evaluation 

The following metrics/scripts are used for evaluation:
1. [BLEU](https://github.com/moses-smt/mosesdecoder/blob/master/scripts/generic/multi-bleu.perl)
1. [METEOR](https://www.cs.cmu.edu/~alavie/METEOR/)
1. [TER](https://www.cs.umd.edu/~snover/tercom/)
1. [PARENT](https://github.com/google-research/language/tree/master/language/table_text_eval)

